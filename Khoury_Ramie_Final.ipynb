{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Khoury_Ramie_Final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkhoury1/MachineLearningShenaniganz/blob/main/Khoury_Ramie_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSdgO40xcP2c"
      },
      "source": [
        "import json\n",
        "from datetime import datetime, date, time, timezone\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import glob\n",
        "import os\n",
        "import string\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlfw1VcQcP2g"
      },
      "source": [
        "***1. Predicting Stock Price Movement***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gguzJfT9cP2g"
      },
      "source": [
        "***b) i) Stock Twits Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYh9G7hvcP2h"
      },
      "source": [
        "Open and Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHZwhIuPcP2h"
      },
      "source": [
        "file_list = glob.glob(os.path.join(os.getcwd(), \"twits\", \"*.txt\"))\n",
        "df_all = {}\n",
        "for file_path in file_list:\n",
        "    with open(file_path) as json_file:\n",
        "        temp = json.load(json_file)\n",
        "    name = \"\".join(list(file_path)[51:]).strip('.txt')\n",
        "    df_all[name] = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQhQPkkTcP2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c3593e-31a9-41d5-86e4-645d723e4dd5"
      },
      "source": [
        "df_all.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtSBNfyScP2n"
      },
      "source": [
        "------- Using just one dataset -------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmkUIpGBcP2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "8e4e5534-67b6-49e4-c4a0-a597448905b2"
      },
      "source": [
        "with open('twits/AXP.txt') as json_file:\n",
        "    axp = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8951eecc95ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twits/AXP.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0maxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twits/AXP.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2IX8VQxcP2q"
      },
      "source": [
        "data = []\n",
        "for i in range(0, len(axp)):\n",
        "    temp = []\n",
        "    date = axp[i]['created_at']\n",
        "    date = ''.join(list(date)[5:16])\n",
        "    date = datetime.strptime(date, '%d %b %Y').date()\n",
        "    temp.append(date)\n",
        "    if axp[i]['sentiment'] != None:\n",
        "        temp.append(axp[i]['sentiment']['class'])\n",
        "    else:\n",
        "        temp.append('None')\n",
        "    data.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEOKAqUGcP2s"
      },
      "source": [
        "df_axp = pd.DataFrame(data, columns = ['Date', 'Sentiment'])\n",
        "df_axp.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMeScE9jcP2v"
      },
      "source": [
        "Moving Average for Polarity (St)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "877NfGfkcP2v"
      },
      "source": [
        "df_new = pd.DataFrame(df_axp.groupby(['Date', 'Sentiment'])['Sentiment'].count())\n",
        "df_new.columns = ['Count']\n",
        "df_new.reset_index(inplace=True)\n",
        "df_new.iloc[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK2RGxHgcP2y"
      },
      "source": [
        "#get list of dates\n",
        "dates = []\n",
        "for i in range(0,len(df_new)):\n",
        "    if df_new.iloc[i]['Date'] not in dates:\n",
        "        dates.append(df_new.iloc[i]['Date'])\n",
        "len(dates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRHf_enQcP20"
      },
      "source": [
        "polarity = []\n",
        "sentiments = ['bullish', 'bearish', 'None']\n",
        "for k in range(0,len(dates)):\n",
        "    dictsent = {}\n",
        "    temp = df_new[df_new['Date'] == dates[k]]\n",
        "    for i in sentiments:\n",
        "        if i in list(temp['Sentiment']):\n",
        "            dictsent[i] = int(temp[temp['Sentiment'] == i]['Count'])\n",
        "        else:\n",
        "            dictsent[i] = 0\n",
        "    dictsent\n",
        "    polarity.append((dictsent['bullish']-dictsent['bearish'])/sum(dictsent.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEtQXt3LcP24"
      },
      "source": [
        "st = []\n",
        "for i in range(0, len(polarity)):\n",
        "    if i == 0:\n",
        "        st.append(None)\n",
        "    elif i == len(polarity)-1:\n",
        "        st.append(None)\n",
        "    else:\n",
        "        add = polarity[i-1]+polarity[i]+polarity[i+1]\n",
        "        st.append(add/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjrgiIHPcP26"
      },
      "source": [
        "Volume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5s2HbNl7cP27"
      },
      "source": [
        "df_new = pd.DataFrame(df_axp.groupby('Date').count())\n",
        "df_new.reset_index(level=0, inplace=True)\n",
        "df_new.sort_values(by=['Date'])\n",
        "df_new.columns = ['Date', 'Count']\n",
        "volume = list(df_new['Count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cxe2bwEcP29"
      },
      "source": [
        "Volume Change (MV1,t)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pX-8AFwcP2-"
      },
      "source": [
        "mv1t = []\n",
        "for index, row in df_new.iterrows():\n",
        "    if index == 0:\n",
        "        mv1t.append(None)\n",
        "    else:\n",
        "        mv1t.append((row['Count']-temp)/temp)\n",
        "    temp = row['Count']\n",
        "print(len(mv1t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqEPumiDcP3A"
      },
      "source": [
        "Average Volume Change(MV10,t)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_uTYD0KcP3B"
      },
      "source": [
        "mv10t = []\n",
        "for i in range(0, len(df_new)):\n",
        "    if i <= 9:\n",
        "        mv10t.append(None)\n",
        "    else:\n",
        "        temp = 0\n",
        "        for k in range(i-10, i):\n",
        "            temp = temp + df_new.iloc[k]['Count']\n",
        "        mv10t.append(df_new.iloc[i]['Count']/temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbFQdSBFcP3E"
      },
      "source": [
        "len(mv10t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tydLb68dcP3G"
      },
      "source": [
        "axp_twit = pd.DataFrame({\n",
        "    'Date':dates, \n",
        "    'Polarity':polarity,\n",
        "    'St': st,\n",
        "    'Volume': volume,\n",
        "    'MV1t': mv1t,\n",
        "    'MV10t:': mv10t})\n",
        "axp_twit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq5IQCincP3J"
      },
      "source": [
        "***ii) Price Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PPUfA19cP3K"
      },
      "source": [
        "axp_price = pd.read_csv('csv/AXP.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIkEOn5fcP3N"
      },
      "source": [
        "#focus only on closing\n",
        "axp_price = axp_price[['Date', 'CLOSE']].sort_values('Date')\n",
        "axp_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHYTU0hfcP3P"
      },
      "source": [
        "***iii) Prediction Target***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "K_-1Xt_wcP3P"
      },
      "source": [
        "day3return = []\n",
        "close = list(axp_price['CLOSE'])\n",
        "for i in range(0, len(close)):\n",
        "    if i < len(close)-3:\n",
        "        temp = (close[i+3]-close[i])/close[i]\n",
        "        day3return.append(temp)\n",
        "    else:\n",
        "        day3return.append(None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vsLYBFtcP3R"
      },
      "source": [
        "day5return = []\n",
        "close = list(axp_price['CLOSE'])\n",
        "for i in range(0, len(close)):\n",
        "    if i < len(close)-5:\n",
        "        temp = (close[i+5]-close[i])/close[i]\n",
        "        day5return.append(temp)\n",
        "    else:\n",
        "        day5return.append(None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Lq1-wncP3T"
      },
      "source": [
        "axp_price['3DayReturn'] = day3return\n",
        "axp_price['5DayReturn'] = day5return\n",
        "axp_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzcG6gorcP3V"
      },
      "source": [
        "***c) Pre-Processing and Exploratory***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1Sg8gY9cP3V"
      },
      "source": [
        "df_all.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d8FUlShcP3X"
      },
      "source": [
        "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
        "             \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", \n",
        "             'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
        "             'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', \n",
        "             'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
        "             'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', \n",
        "             'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
        "             'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
        "             'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', \n",
        "             'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', \n",
        "             't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \n",
        "             've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \n",
        "             \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \n",
        "             \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
        "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m87xjpuucP3Z"
      },
      "source": [
        "def checktag(string):\n",
        "    string = list(string)\n",
        "    count = 0\n",
        "    for i in string:\n",
        "        if i == '$':\n",
        "            count = count+1\n",
        "    if count > 2:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k_1GR7CcP3d"
      },
      "source": [
        "doc = []\n",
        "date = []\n",
        "temp = df_all['AXP']\n",
        "for i in range(0, len(temp)):\n",
        "    if checktag(temp[i]['body']) == False:\n",
        "        words = temp[i]['body'].split(' ')\n",
        "        doc.append(words)\n",
        "        dat = \"\".join(list(temp[3]['created_at'])[5:16])\n",
        "        date.append(datetime.strptime(dat, '%d %b %Y').date())\n",
        "len(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJkGu7Y2cP3f"
      },
      "source": [
        "words = temp[20]['body'].split(' ')\n",
        "words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7GcZCH8cP3h"
      },
      "source": [
        "checktag(temp[20]['body'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyF5wD2qcP3j"
      },
      "source": [
        "for i in list(temp[10]['body']):\n",
        "    if "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy1mGymlcP3l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}